ğŸ§  Chat LLM Local con OpenVINO + Carga de PDFs + BÃºsqueda en Internet
VersiÃ³n Mayo 2025 â€” Autor: JC Llanos V.

ğŸ“§ jcllanosv@hotmail.com

ğŸ”— https://www.linkedin.com/in/jcllanosv/

ğŸš€ DescripciÃ³n General

Este proyecto implementa un chat conversacional local potenciado por modelos LLM optimizados con OpenVINO, permitiendo:

âœ” ElecciÃ³n de mÃºltiples modelos (TinyLlama, Phi, Mistral, DeepSeek, Qwen, Gemma, StarCoder2, etc.)
âœ” EjecuciÃ³n acelerada en CPU o Intel iGPU
âœ” Guardado automÃ¡tico de modelos convertidos para uso offline
âœ” Lectura y carga de archivos PDF con extracciÃ³n automÃ¡tica de texto
âœ” Comandos especiales para resumir, comentar y manejar contenido del PDF
âœ” IntegraciÃ³n opcional de bÃºsquedas en Internet (DuckDuckGo Search) para respuestas con contexto actualizado
âœ” Historial conversacional acotado para mantener el rendimiento
âœ” Interfaz simple por consola y selector de PDF mediante una ventana GUI con Tkinter

Este programa funciona completamente local, salvo cuando se activa la opciÃ³n de bÃºsqueda en internet.

ğŸ“¦ Funcionalidades Principales
ğŸ” 1. SelecciÃ³n de Modelos LLM

El script incluye una lista extensa de modelos ya optimizados para OpenVINO, incluyendo:

TinyLlama

Phi-2 y Phi-1.5

StarCoder2 (enfocado en cÃ³digo)

CodeGen2

DeepSeek-R1 Qwen (1.5B y 7B)

Mistral 7B Instruct

Zephyr 7B

Dolly v2

RedPajama

Gemma 2B

Qwen2 (0.5B y 1.5B)

DistilGPT-2

TinyLlama original

Muchos vienen en formato INT4/INT8 para mÃ¡ximo rendimiento en GPU Intel.

Todos los modelos se descargan o convierten una sola vez y luego se reutilizan desde la carpeta:

mis_modelos_openvino/

ğŸ“„ 2. Carga y Procesamiento de PDF

Incluye soporte completo para PDFs mediante PyMuPDF:

Selector grÃ¡fico para elegir archivos (tkinter)

ExtracciÃ³n completa de texto

Advertencias si el PDF no contiene texto

LÃ­mite configurable de caracteres para evitar prompts excesivos

Comandos disponibles:

Comando	FunciÃ³n
!cargar_pdf	Selecciona un PDF desde el explorador
!resumir_pdf	Genera un resumen usando el LLM
!comentar_pdf	Analiza y comenta el PDF
!olvidar_pdf	Borra el PDF cargado del contexto
ğŸŒ 3. BÃºsqueda en Internet (opcional)

Al activar:

ENABLE_INTERNET_SEARCH = True


El asistente puede:

Buscar informaciÃ³n reciente mediante DuckDuckGo

Resumir resultados

Incluir contexto web en las respuestas

Ideal para respuestas que requieren actualidad (ej.: leyes, noticias, eventos recientes).

ğŸ§© 4. Chat Interactivo y Persistente

El sistema mantiene:

Historial de turnos configurable

Manejo robusto de errores

Control automÃ¡tico de temperatura, top_k, top_p y generaciÃ³n de tokens

Limpieza automÃ¡tica del contexto en cada carga de modelo

ğŸ› ï¸ TecnologÃ­as Utilizadas
TecnologÃ­a	Uso
Python 3.10+	Lenguaje principal
OpenVINO Runtime	Inferencia acelerada
Optimum Intel (HuggingFace)	Carga/convertir modelos LLM
Transformers	TokenizaciÃ³n
PyMuPDF (fitz)	Lectura de PDF
Tkinter	Selector grÃ¡fico de archivos
DuckDuckGo Search (DDGS)	BÃºsquedas web (opcional)
ğŸ“ Estructura del Proyecto
/
â”œâ”€â”€ mis_modelos_openvino/     # (Se crea automÃ¡ticamente)
â”œâ”€â”€ README.md                 
â””â”€â”€ main.py                   # Este script principal

â–¶ï¸ CÃ³mo Ejecutarlo
1. Instalar dependencias
pip install openvino==2024.4.0
pip install optimum[intel]
pip install transformers
pip install PyMuPDF
pip install duckduckgo_search
pip install tkinter  # En Linux puede requerir paquete del sistema

2. Ejecutar el script
python main.py

3. Seleccionar un modelo

El programa mostrarÃ¡ un listado, por ejemplo:

 1. OpenVINO: TinyLlama 1.1B Chat (INT8)
 2. OpenVINO: Mistral 7B Instruct (INT4)
 3. OpenVINO: DeepSeek-Qwen 1.5B (INT4)
 ...

ğŸ§­ CÃ³mo Usarlo

Una vez cargado el modelo:

Listo para chatear...
Comandos PDF: !cargar_pdf, !resumir_pdf, !comentar_pdf, !olvidar_pdf


Ejemplo bÃ¡sico:

TÃº: Â¿CuÃ¡l es la capital de Chile?


Ejemplo usando PDF:

TÃº: !cargar_pdf
TÃº: !resumir_pdf
TÃº: Explica el capÃ­tulo 2 del PDF


Ejemplo con internet:

TÃº: Â¿CuÃ¡l es la situaciÃ³n actual de la Ley 21.659 en Chile?

âš ï¸ Consideraciones

Algunos modelos requieren trust_remote_code=True.

Modelos grandes (7B+) pueden requerir GPU Intel Arc o mucha RAM.

La bÃºsqueda en internet puede producir resultados variables segÃºn regiÃ³n (cl-es preconfigurado).

ğŸ§‘â€ğŸ’» Autor

JC Llanos V.
ğŸ”— https://www.linkedin.com/in/jcllanosv/
